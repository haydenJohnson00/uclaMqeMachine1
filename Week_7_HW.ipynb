{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z9sYcDE-qV7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.) Import an asset price from Yahoo Finance"
      ],
      "metadata": {
        "id": "6dJuZDx9qWeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install yfinance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 998
        },
        "id": "QxUUnTVTrx3m",
        "outputId": "2eb52e99-29d6-4363-acc3-c84f132b8237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.2.12-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 KB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.8/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.8/dist-packages (from yfinance) (0.0.11)\n",
            "Collecting requests>=2.26\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.8/dist-packages (from yfinance) (4.9.2)\n",
            "Collecting html5lib>=1.1\n",
            "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 KB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.8/dist-packages (from yfinance) (2022.7.1)\n",
            "Collecting frozendict>=2.3.4\n",
            "  Downloading frozendict-2.3.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.2/111.2 KB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting beautifulsoup4>=4.11.1\n",
            "  Downloading beautifulsoup4-4.11.2-py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 KB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cryptography>=3.3.2\n",
            "  Downloading cryptography-39.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from yfinance) (1.22.4)\n",
            "Collecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.4-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=3.3.2->yfinance) (1.15.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from html5lib>=1.1->yfinance) (1.15.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (3.0.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=3.3.2->yfinance) (2.21)\n",
            "Installing collected packages: soupsieve, requests, html5lib, frozendict, cryptography, beautifulsoup4, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.25.1\n",
            "    Uninstalling requests-2.25.1:\n",
            "      Successfully uninstalled requests-2.25.1\n",
            "  Attempting uninstall: html5lib\n",
            "    Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed beautifulsoup4-4.11.2 cryptography-39.0.1 frozendict-2.3.5 html5lib-1.1 requests-2.28.2 soupsieve-2.4 yfinance-0.2.12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3bcwJb4rp93",
        "outputId": "abacaf45-dfcb-4467-bc5d-e16e6771d2cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "\n",
        "\n",
        "########################################\n",
        "####Pick your ticker and time period####\n",
        "########################################\n",
        "stock_data = yf.download(\"COST\", start=\"1990-01-01\", end=\"2022-02-21\")\n",
        "\n",
        "\n",
        "\n",
        "# Preprocess data\n",
        "scaled_data = np.array(stock_data[\"Close\"].pct_change().dropna()).reshape(-1,1)\n",
        "\n",
        "\n",
        "# Split data into training and test sets\n",
        "training_data_len = int(len(scaled_data) * 0.8)\n",
        "train_data = scaled_data[0:training_data_len, :]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.) Create your x_train/y_train data so that your RNN uses percentage change data to make a binary forecast where the stock moves up or down the next day\n",
        "# Build an RNN Architecture accordingly"
      ],
      "metadata": {
        "id": "foHoGy9hq3_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "\n",
        "#############################################################\n",
        "####Pick your input size and edit to make binary forecast####\n",
        "#############################################################\n",
        "input_size = 8\n",
        "for i in range(input_size, len(train_data)):\n",
        "    x_train.append(train_data[i-input_size:i, 0])\n",
        "    if train_data[i, 0] > train_data[i-1, 0]:\n",
        "        y_train.append(1)\n",
        "    else:\n",
        "        y_train.append(0)\n",
        "\n",
        "\n",
        "x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "\n",
        "###################################\n",
        "####Build Your RNN Architecture####\n",
        "###################################\n",
        "model = Sequential()\n",
        "model.add(LSTM(x_train.shape[1], return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
        "#Examples\n",
        "#model.add(LSTM(50, return_sequences=False))\n",
        "model.add(Dense(1))\n",
        "#\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(x_train, y_train, batch_size=1, epochs=3)"
      ],
      "metadata": {
        "id": "5qGFB5HfqcVd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fe2343e-0b0f-4676-a410-25f8c4a92194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "6469/6469 [==============================] - 28s 4ms/step - loss: 0.2577\n",
            "Epoch 2/3\n",
            "6469/6469 [==============================] - 24s 4ms/step - loss: 0.2501\n",
            "Epoch 3/3\n",
            "6469/6469 [==============================] - 25s 4ms/step - loss: 0.2493\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9160507d60>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p3BlSFA8Na77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.) Test your model and compare insample Accurracy, insample random walk assumption Accuracy, Out of sample Accuracy and out of sample random walk assumption Accuracy using a bar chart"
      ],
      "metadata": {
        "id": "yFhO9vMjsWPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_data = scaled_data[training_data_len - input_size:, :]\n",
        "\n",
        "x_test = []\n",
        "#y_test = np.array(stock_data[[\"Close\"]].pct_change().dropna())[training_data_len:, :]\n",
        "y_test = []\n",
        "for i in range(input_size, len(test_data)):\n",
        "    x_test.append(test_data[i-input_size:i, 0])\n",
        "    y_test.append(1 if train_data[i, 0] > 0 else 0)\n",
        "\n",
        "x_test = np.array(x_test)\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "predictions = model.predict(x_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "r1Xj6Ji-rwnM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e4348a8-7805-46fa-b62c-96d91040a51c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51/51 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "I0S1r0R7d1Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In Random Walk\n",
        "y_train[1:] # Actual\n",
        "y_train[:-1] # Prediction\n",
        "\n",
        "# OOS Random Walk\n",
        "y_test[1:] # Actual\n",
        "y_test[:-1] # Prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dvEX9mng8dA",
        "outputId": "c5baf771-35e1-41fc-d526-eb859bc7f667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In sample accuracy\n",
        "in_sample_predictions = model.predict(x_train)\n",
        "in_sample_accuracy = np.mean(np.round(in_sample_predictions) == y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WkskpdMVAk1",
        "outputId": "f00e5da3-8078-4397-e428-fbcda3598a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "203/203 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In sample random walk accuracy\n",
        "in_sample_random_walk_accuracy = np.mean(y_train[1:] == y_train[:-1])"
      ],
      "metadata": {
        "id": "GDbzoDfBVCgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Out of sample accuracy\n",
        "out_of_sample_predictions = model.predict(x_test)\n",
        "out_of_sample_accuracy = np.mean(np.round(out_of_sample_predictions) == y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpOlq5S_2Wxh",
        "outputId": "bd8856fc-e511-4fdb-b6d9-b912a4f9fc15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51/51 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Out of sample random walk accuracy\n",
        "out_of_sample_random_walk_accuracy = np.mean(y_test[1:] == y_test[:-1])"
      ],
      "metadata": {
        "id": "LtQyMEwv2WiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "fpnS0z-nZv9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up data for bar chart\n",
        "accuracy_scores = [in_sample_accuracy, in_sample_random_walk_accuracy, out_of_sample_accuracy, out_of_sample_random_walk_accuracy]\n",
        "labels = ['In-sample\\nRNN accuracy', 'In-sample\\nrandom walk accuracy', 'Out-of-sample\\nRNN accuracy', 'Out-of-sample\\nrandom walk accuracy']\n",
        "colors = ['b', 'r', 'b', 'r']\n",
        "\n",
        "# Create bar chart\n",
        "fig, ax = plt.subplots(figsize=(8,6))\n",
        "ax.bar(labels, accuracy_scores, color=colors)\n",
        "ax.set_ylim([0, 1])\n",
        "ax.set_ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "6EP66_Z0VFLC",
        "outputId": "76ff7512-1da1-405d-fa29-71dd4e08549a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "35O_7b3iX1cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZP_GJ8X-Wkln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.) Plot in and out of sample accuracy"
      ],
      "metadata": {
        "id": "8bncNwh8tKiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make predictions on full dataset\n",
        "\n",
        "test_predict = model.predict(x_test)\n",
        "test_predictions = (test_predict+1).reshape(1,-1) * np.cumprod(y_test+1)\n",
        "\n",
        "train_predict = model.predict(x_train)\n",
        "train_predictions = (train_predict+1).reshape(1,-1) * np.cumprod(y_train+1)\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(stock_data[:training_data_len- input_size].index, np.cumprod(y_train+1), label=\"Training Data\")\n",
        "plt.plot(stock_data[:training_data_len- input_size].index, train_predictions[0], label=\"Training Predictions\")\n",
        "end_val = np.cumprod(y_train+1)[-1]\n",
        "test_predict = model.predict(x_test)\n",
        "test_predictions = (test_predict+1).reshape(1,-1) * (np.cumprod((y_test+1))*end_val)\n",
        "plt.plot(stock_data[training_data_len+1:].index, np.cumprod((y_test+1))*end_val,label=\"Test Data\")\n",
        "plt.plot(stock_data[training_data_len+1:].index, test_predictions[0], label=\"Test Predictions\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Stock Price\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d698mdExtfHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jVPe8djTn1_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QCY8DfMEtUln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5.) Write an observation/conclusion about the graphs from Q4 and Q3"
      ],
      "metadata": {
        "id": "bK_jyyEEtTUB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The out of sample random walk accuracy is 0, meaning that the predictions made using the random walk assumption (i.e., using the previous observation as the prediction for the current observation) were all incorrect. This is not unexpected, as stock prices are generally known to be difficult to predict using a simple random walk model.\n",
        "\n",
        "Given this, the fact that the out of sample RNN accuracy is 0.6 suggests that the RNN model is performing better than the random walk model in predicting stock prices. Additionally, the in-sample RNN accuracy of 0.5 indicates that the model is capturing some of the underlying patterns in the training data, although there may still be room for improvement. Overall, these results suggest that the RNN model is a promising approach for predicting stock prices."
      ],
      "metadata": {
        "id": "bd3NRd8paDmj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FlD_yx0cshJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N5fbjajz-YCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JKaNjoQlBPbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.) Create a parameter for number of lags in your input layer. Do a 3-fold CV to test three different time lags. i.e. Tested using 5,10,20 days of previous price data to forecast"
      ],
      "metadata": {
        "id": "pFtrp-lmtw6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "# Define the Keras model\n",
        "###Edit here to create your optimizer\n",
        "# Define the Keras model\n",
        "def create_model(input_size):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(50, return_sequences=True, input_shape=(input_size, 1)))\n",
        "    model.add(LSTM(50, return_sequences=False))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Wrap the Keras model in a scikit-learn compatible estimator\n",
        "model = KerasRegressor(build_fn=create_model, verbose=0)\n",
        "\n",
        "# Define the hyperparameters to search over\n",
        "param_grid = {'batch_size': [10, 20, 100],\n",
        "              'epochs': [1],\n",
        "              'input_size':[5,10,20]}\n",
        "\n",
        "# Perform the grid search over the hyperparameters\n",
        "param_grid = {'input_size': [5, 10, 20]}\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(x_train, y_train)\n",
        "\n",
        "# Print the results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kEOQ6TO0-Fnw",
        "outputId": "86b48ebb-3455-4140-9f1a-e0acd4737182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-9b2c2e0db899>:17: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasRegressor(build_fn=create_model, verbose=0)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "9 fits failed out of a total of 9.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n",
            "    history = self.model.fit(x, y, **fit_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/tmp/__autograph_generated_fileb8rxgtoe.py\", line 15, in tf__train_function\n",
            "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
            "ValueError: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1249, in train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1233, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1222, in run_step  **\n",
            "        outputs = model.train_step(data)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1023, in train_step\n",
            "        y_pred = self(x, training=True)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
            "        raise e.with_traceback(filtered_tb) from None\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n",
            "        raise ValueError(\n",
            "\n",
            "    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 5, 1), found shape=(None, 8, 1)\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n",
            "    history = self.model.fit(x, y, **fit_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/tmp/__autograph_generated_filew6kz694p.py\", line 15, in tf__train_function\n",
            "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
            "ValueError: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1249, in train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1233, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1222, in run_step  **\n",
            "        outputs = model.train_step(data)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1023, in train_step\n",
            "        y_pred = self(x, training=True)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
            "        raise e.with_traceback(filtered_tb) from None\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n",
            "        raise ValueError(\n",
            "\n",
            "    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 5, 1), found shape=(None, 8, 1)\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n",
            "    history = self.model.fit(x, y, **fit_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/tmp/__autograph_generated_filew6kz694p.py\", line 15, in tf__train_function\n",
            "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
            "ValueError: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1249, in train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1233, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1222, in run_step  **\n",
            "        outputs = model.train_step(data)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1023, in train_step\n",
            "        y_pred = self(x, training=True)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
            "        raise e.with_traceback(filtered_tb) from None\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n",
            "        raise ValueError(\n",
            "\n",
            "    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 5, 1), found shape=(None, 8, 1)\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n",
            "    history = self.model.fit(x, y, **fit_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/tmp/__autograph_generated_fileb8rxgtoe.py\", line 15, in tf__train_function\n",
            "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
            "ValueError: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1249, in train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1233, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1222, in run_step  **\n",
            "        outputs = model.train_step(data)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1023, in train_step\n",
            "        y_pred = self(x, training=True)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
            "        raise e.with_traceback(filtered_tb) from None\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n",
            "        raise ValueError(\n",
            "\n",
            "    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 10, 1), found shape=(None, 8, 1)\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n",
            "    history = self.model.fit(x, y, **fit_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/tmp/__autograph_generated_fileb8rxgtoe.py\", line 15, in tf__train_function\n",
            "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
            "ValueError: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1249, in train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1233, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1222, in run_step  **\n",
            "        outputs = model.train_step(data)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1023, in train_step\n",
            "        y_pred = self(x, training=True)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
            "        raise e.with_traceback(filtered_tb) from None\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n",
            "        raise ValueError(\n",
            "\n",
            "    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 10, 1), found shape=(None, 8, 1)\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n",
            "    history = self.model.fit(x, y, **fit_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/tmp/__autograph_generated_filew6kz694p.py\", line 15, in tf__train_function\n",
            "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
            "ValueError: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1249, in train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1233, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1222, in run_step  **\n",
            "        outputs = model.train_step(data)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1023, in train_step\n",
            "        y_pred = self(x, training=True)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
            "        raise e.with_traceback(filtered_tb) from None\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n",
            "        raise ValueError(\n",
            "\n",
            "    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 10, 1), found shape=(None, 8, 1)\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n",
            "    history = self.model.fit(x, y, **fit_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/tmp/__autograph_generated_fileb8rxgtoe.py\", line 15, in tf__train_function\n",
            "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
            "ValueError: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1249, in train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1233, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1222, in run_step  **\n",
            "        outputs = model.train_step(data)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1023, in train_step\n",
            "        y_pred = self(x, training=True)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
            "        raise e.with_traceback(filtered_tb) from None\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n",
            "        raise ValueError(\n",
            "\n",
            "    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 20, 1), found shape=(None, 8, 1)\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n",
            "    history = self.model.fit(x, y, **fit_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/tmp/__autograph_generated_filew6kz694p.py\", line 15, in tf__train_function\n",
            "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
            "ValueError: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1249, in train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1233, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1222, in run_step  **\n",
            "        outputs = model.train_step(data)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1023, in train_step\n",
            "        y_pred = self(x, training=True)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
            "        raise e.with_traceback(filtered_tb) from None\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n",
            "        raise ValueError(\n",
            "\n",
            "    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 20, 1), found shape=(None, 8, 1)\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n",
            "    history = self.model.fit(x, y, **fit_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/tmp/__autograph_generated_fileb8rxgtoe.py\", line 15, in tf__train_function\n",
            "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
            "ValueError: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1249, in train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1233, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1222, in run_step  **\n",
            "        outputs = model.train_step(data)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1023, in train_step\n",
            "        y_pred = self(x, training=True)\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
            "        raise e.with_traceback(filtered_tb) from None\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n",
            "        raise ValueError(\n",
            "\n",
            "    ValueError: Input 0 of layer \"sequential_4\" is incompatible with the layer: expected shape=(None, 20, 1), found shape=(None, 8, 1)\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-9b2c2e0db899>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'input_size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Print the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 5, 1), found shape=(None, 8, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QA_gAupmA_8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vfH6js5EB2wu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}